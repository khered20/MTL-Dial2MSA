{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNCfR93vsl2qheAi4QmdyJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khered20/MTL-Dial2MSA/blob/main/MTLtrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ff72fHu1rVoV"
      },
      "outputs": [],
      "source": [
        "!pip install sacremoses sacrebleu  -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Clone your GitHub repository\n",
        "if not os.path.exists(\"MTL-Dial2MSA\"):\n",
        "    !git clone https://github.com/khered20/MTL-Dial2MSA.git\n",
        "    %cd MTL-Dial2MSA\n",
        "else:\n",
        "    %cd MTL-Dial2MSA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctNeI9Lsrc8k",
        "outputId": "5261406e-4ce8-415d-fada-280e168e9e2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTL-Dial2MSA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Clone your GitHub repository\n",
        "if not os.path.exists(\"Dial2MSA-Verified\"):\n",
        "    !git clone https://github.com/khered20/Dial2MSA-Verified.git"
      ],
      "metadata": {
        "id": "rGCdxpuUrdKn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob, os\n",
        "import os\n",
        "\n",
        "# Create the 'data' directory if it doesn't exist\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data\")\n",
        "\n",
        "\n",
        "# Define mapping of dialects to msa column name\n",
        "msa_mapping = {\n",
        "    \"egy\": \"msa\",\n",
        "    \"mgr\": \"msa\",\n",
        "    \"glf\": \"msa_verified\",\n",
        "    \"lev\": \"msa_verified\"\n",
        "}\n",
        "\n",
        "def merge_csvs(folder):\n",
        "    dfs = []\n",
        "    files = glob.glob(os.path.join(\"Dial2MSA-Verified\", folder, \"*.csv\"))\n",
        "    for f in files:\n",
        "        dialect = f.split(\"/\")[-1].split(\"_\")[0]   # e.g., \"egy_train.csv\" -> \"egy\"\n",
        "        msa_col = msa_mapping[dialect]             # choose correct msa column\n",
        "        df = pd.read_csv(f)\n",
        "\n",
        "        # Extract required columns\n",
        "        df = df[[\"cleanedtweet2\", msa_col]].rename(\n",
        "            columns={\"cleanedtweet2\": \"dialect_sentence\", msa_col: \"msa_translation\"}\n",
        "        )\n",
        "        df[\"dialect_label\"] = dialect.upper()\n",
        "\n",
        "        dfs.append(df)\n",
        "    merged = pd.concat(dfs, ignore_index=True)\n",
        "    merged = merged[[\"dialect_label\", \"dialect_sentence\", \"msa_translation\"]]\n",
        "    return merged\n",
        "\n",
        "# Merge train & dev\n",
        "train_df = merge_csvs(\"train\")\n",
        "dev_df   = merge_csvs(\"dev\")\n",
        "\n",
        "print(\"Train samples:\", len(train_df))\n",
        "print(\"Dev samples:\", len(dev_df))\n",
        "print(train_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAhV24ZMrdZY",
        "outputId": "a7144a82-3d40-4eb9-a838-089fa52b93ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 23087\n",
            "Dev samples: 800\n",
            "  dialect_label                                   dialect_sentence  \\\n",
            "0           EGY  جروبس الواتس بتاعه العائلات دى عقاب من ربنا والله   \n",
            "1           EGY  جروبس الواتس بتاعه العائلات دى عقاب من ربنا والله   \n",
            "2           EGY  زاي لن محدش بيطلب الاهتمام محدش يستني من حد هي...   \n",
            "3           EGY  زاي لن محدش بيطلب الاهتمام محدش يستني من حد هي...   \n",
            "4           EGY        مبعرفش اكدب ديه ميزه بس فالعالم ده اكبر عيب   \n",
            "\n",
            "                                     msa_translation  \n",
            "0       جروب الواتس الخاص بهذه العائلات عقاب من الله  \n",
            "1                     مجموعة الواتس هذة عقاب من اللة  \n",
            "2  طالما لن يطلب شخص ما الاهتمام من أحد سيرتاح هذ...  \n",
            "3            مثل اى احد بيطلب الاهتمام من احد هيرتاح  \n",
            "4  لا أعرف الكذب مهذه ميزه لكن فى هذا العالم هذا ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Available dialect labels:\", train_df['dialect_label'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhh_y7tbzwMS",
        "outputId": "798e1281-9d29-4fda-f6e2-3822d573c369"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available dialect labels: ['EGY' 'MGR' 'LEV' 'GLF']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Optional if you want augmenting the data with MSA pairs\n",
        "# Duplicate train_df\n",
        "train_df_msa = train_df.copy()\n",
        "\n",
        "# Change dialect_label to 'MSA' in the duplicated DataFrame\n",
        "train_df_msa['dialect_label'] = 'MSA'\n",
        "train_df_msa['dialect_sentence'] = train_df_msa['msa_translation']\n",
        "\n",
        "# Concatenate the original and duplicated DataFrames\n",
        "train_df = pd.concat([train_df, train_df_msa], ignore_index=True)\n",
        "\n",
        "train_df = train_df.drop_duplicates([\"dialect_sentence\", \"msa_translation\"], keep=\"first\")\n",
        "# Display the first few rows and the new length to verify\n",
        "print(\"New length of train_df:\", len(train_df))\n",
        "print(train_df.head())\n",
        "print(\"Available dialect labels:\", train_df['dialect_label'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypEIqjOe5JvS",
        "outputId": "0d6f998a-bd49-447a-b755-9e300afedb39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New length of train_df: 45760\n",
            "  dialect_label                                   dialect_sentence  \\\n",
            "0           EGY  جروبس الواتس بتاعه العائلات دى عقاب من ربنا والله   \n",
            "1           EGY  جروبس الواتس بتاعه العائلات دى عقاب من ربنا والله   \n",
            "2           EGY  زاي لن محدش بيطلب الاهتمام محدش يستني من حد هي...   \n",
            "3           EGY  زاي لن محدش بيطلب الاهتمام محدش يستني من حد هي...   \n",
            "4           EGY        مبعرفش اكدب ديه ميزه بس فالعالم ده اكبر عيب   \n",
            "\n",
            "                                     msa_translation  \n",
            "0       جروب الواتس الخاص بهذه العائلات عقاب من الله  \n",
            "1                     مجموعة الواتس هذة عقاب من اللة  \n",
            "2  طالما لن يطلب شخص ما الاهتمام من أحد سيرتاح هذ...  \n",
            "3            مثل اى احد بيطلب الاهتمام من احد هيرتاح  \n",
            "4  لا أعرف الكذب مهذه ميزه لكن فى هذا العالم هذا ...  \n",
            "Available dialect labels: ['EGY' 'MGR' 'LEV' 'GLF' 'MSA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "train_df.to_csv(\"data/All_train_mtl.csv\", index=False)\n",
        "dev_df.to_csv(\"data/All_dev_mtl.csv\", index=False)"
      ],
      "metadata": {
        "id": "vxDJc3cz6nBC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k4p249tS0YVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./MTL-Dial2MSA')\n",
        "\n",
        "from mtl.dataset import create_data_loaders\n",
        "from mtl.models import MultiTaskT5, MultiTaskMBart\n",
        "from mtl.train import train\n",
        "from mtl.utils import cleanup\n",
        "from transformers import AutoTokenizer, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "0gmr4hAkuy6p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#SAVE_PATH = \"saved_models/mtl_AraT5\"\n",
        "#MODEL_NAME = \"UBC-NLP/AraT5v2-base-1024\"\n",
        "#tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "#model = MultiTaskT5(num_labels=5, pretrained_model=MODEL_NAME).to(device)\n",
        "batch_size = 16\n",
        "max_length = 128\n",
        "num_epochs = 3\n",
        "alpha=0.5\n",
        "SAVE_PATH = \"fn/mtl_AraBART\"\n",
        "MODEL_NAME=\"moussaKam/AraBART\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = MultiTaskMBart(num_labels=5, pretrained_model=MODEL_NAME).to(device)\n",
        "\n",
        "\n",
        "train_loader, val_loader, tokenizer = create_data_loaders(\n",
        "    \"data/All_train_mtl.csv\", \"data/All_dev_mtl.csv\",\n",
        "    tokenizer, batch_size=batch_size, max_length=max_length\n",
        ")\n",
        "\n",
        "\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH+'/trns')\n",
        "tokenizer.save_pretrained(SAVE_PATH+'/cls')\n",
        "tokenizer.save_pretrained(SAVE_PATH+'/last')\n",
        "\n",
        "config = {\n",
        "    \"base_model\": MODEL_NAME,\n",
        "    \"num_labels\": 5,\n",
        "    \"max_length\": max_length,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"custom_parameters\": {\n",
        "        \"alpha\": alpha,\n",
        "    }\n",
        "}\n",
        "\n",
        "config_path = SAVE_PATH+'/config.json'\n",
        "with open(config_path, 'w') as json_file:\n",
        "    json.dump(config, json_file, indent=4)\n",
        "\n",
        "config_path = SAVE_PATH+'/trns'+'/config.json'\n",
        "with open(config_path, 'w') as json_file:\n",
        "    json.dump(config, json_file, indent=4)\n",
        "\n",
        "config_path = SAVE_PATH+'/cls'+'/config.json'\n",
        "with open(config_path, 'w') as json_file:\n",
        "    json.dump(config, json_file, indent=4)\n",
        "\n",
        "config_path = SAVE_PATH+'/last'+'/config.json'\n",
        "with open(config_path, 'w') as json_file:\n",
        "    json.dump(config, json_file, indent=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoX8Xj_PuzJV",
        "outputId": "368b13c6-5712-4e00-cc0a-a892543231d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "num_epochs = 2\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * num_epochs\n",
        ")\n"
      ],
      "metadata": {
        "id": "bfO3YICJwwEI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_bleu, best_f1 = train(\n",
        "    model, train_loader, optimizer, scheduler, device,\n",
        "    val_loader, tokenizer, epochs=num_epochs, save_path=SAVE_PATH,alpha=alpha\n",
        ")\n",
        "print(\"Training finished!\")\n",
        "print(\"Best BLEU:\", best_bleu)\n",
        "print(\"Best F1:\", best_f1)\n",
        "\n",
        "cleanup()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5pGkfy-uzY1",
        "outputId": "9bfc12b2-9337-4bf5-8bf9-4e151c7a2ffa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 50/50 [00:30<00:00,  1.66it/s, loss=2.5]\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.58.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev Epoch 1, BLEU Score: 14.92817171180575, F1 Score: 0.21398593530239102, -best bleu: 14.92817171180575, best f1: 0.21398593530239102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 50/50 [00:29<00:00,  1.69it/s, loss=2.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev Epoch 2, BLEU Score: 16.62205440878057, F1 Score: 0.29885309400094473, -best bleu: 16.62205440878057, best f1: 0.29885309400094473\n",
            "Training finished!\n",
            "Best BLEU: 16.62205440878057\n",
            "Best F1: 0.29885309400094473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mtl.predict import predict\n",
        "\n",
        "samples = [\"إزيك عامل إيه؟\", \"شلونك يا خوي؟\"]\n",
        "outputs = predict(model, tokenizer, samples, device)\n",
        "\n",
        "for o in outputs:\n",
        "    print(\"\\nInput:\", o[\"input\"])\n",
        "    print(\"Predicted Dialect:\", o[\"dialect\"])\n",
        "    print(\"Predicted Translation:\", o[\"translation\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTN0skZwuzvN",
        "outputId": "7fd9a8d9-84f5-4dd1-a879-1b5496c65151"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input: إزيك عامل إيه؟\n",
            "Predicted Dialect: LEV\n",
            "Predicted Translation: ماذا حدث؟\n",
            "\n",
            "Input: شلونك يا خوي؟\n",
            "Predicted Dialect: LEV\n",
            "Predicted Translation: كيف حالك يا خوي؟\n"
          ]
        }
      ]
    }
  ]
}